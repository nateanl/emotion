{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emotion Classification using word2vec and speech features\n",
    "\n",
    "### First, use Mecab to tokenize japanese corpus, then use Google word2vec tool to train a word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm, naive_bayes, ensemble, neural_network, metrics\n",
    "from sklearn.model_selection import cross_val_predict, train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "word_vectors = word2vec.Word2Vec.load('word2vec/word2vec.gensim.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('工藤新一', 0.8142108917236328),\n",
       " ('扮する', 0.8039429187774658),\n",
       " ('柳生十兵衛', 0.7999906539916992),\n",
       " ('怪盗キッド', 0.7948559522628784),\n",
       " ('名探偵', 0.7929961085319519),\n",
       " ('メインヒロイン', 0.7890465259552002),\n",
       " ('サイドストーリー', 0.7831361889839172),\n",
       " ('マペット', 0.7783994078636169),\n",
       " ('怪盗', 0.7781833410263062),\n",
       " ('中村主水', 0.7774820327758789)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar('江戸川コナン')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looks like the model works well, \"江戸川コナン\" is the main character's name of \"Detective Conan\", his true name should be \"工藤新一\". So this model can capture the semantic meaning of the character..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4850"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##process the trans\n",
    "trans_list = ['01_MAD_1.wav', '01_MMK_1.wav', '02_MTN.wav', '03_FTY.wav', '05_MYH.wav', '01_MAD_2.wav', '01_MMK_2.wav', '03_FMA.wav', '04_MNN.wav']\n",
    "trans_list = [element.replace('wav','txt') for element in trans_list]\n",
    "count = {}\n",
    "for file in trans_list:\n",
    "    f = open('trans/'+file)\n",
    "    for line in f:\n",
    "        if not line == '':\n",
    "            index = file.split('txt')[0] + line.split(',')[0]\n",
    "            content = line.split(',')\n",
    "            content = content[len(content)-1]\n",
    "            content = content.replace('{','')\n",
    "            content = content.replace('}','')\n",
    "            content = content.replace('\\n','')\n",
    "            count[index] = content\n",
    "ins_list = []\n",
    "not_intside = ['03_FTY.215','04_MNN.777', '04_MNN.267','04_MNN.417','01_MMK_1.178']\n",
    "inst = open('instances.txt')\n",
    "for line in inst:\n",
    "    line = line.split('\\n')[0]\n",
    "    if line not in not_intside:\n",
    "        ins_list.append(line)\n",
    "len(ins_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract all sentences from transcript, store all sentences in the dictionary whose ids are the instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('./emobase2010.arff')\n",
    "not_class = ['NEU','UNK','OTH',' )']\n",
    "content = []\n",
    "speech = []\n",
    "labels = []\n",
    "for line in f:\n",
    "    if ',' in line and \"'\" in line:\n",
    "        label = line.split(',')[-1].replace('\\n','')\n",
    "        if label not in not_class:\n",
    "            labels.append(label)\n",
    "            feature = line.split(\"',\")[1]\n",
    "            speech.append(feature)\n",
    "            line = line.split(',')[0].replace(\"'\",\"\")\n",
    "            if line not in not_intside:\n",
    "                content.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the data with the three emotion labels and the one without any label.\n",
    "### Extract the speech features from arff file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SAD', 'JOY', 'FEA', 'DIS', 'ANT', 'SUR', 'ANG', 'ACC'}\n"
     ]
    }
   ],
   "source": [
    "label = set(labels)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for element in content:\n",
    "    sentences.append(count[element])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the transcript sentences to a text file.\n",
    "### Use Mecab software to tokenize sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2742\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences))\n",
    "f = open('trans_text.txt','w')\n",
    "for s in sentences:\n",
    "    f.write(s+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the average of word vectors in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trans_vectors = []\n",
    "f = open('trans_tokenized.txt')\n",
    "for line in f:\n",
    "    tokens = line.split()\n",
    "    temp = [0.0]*50\n",
    "    for token in tokens:\n",
    "        if token in word_vectors:\n",
    "            temp =[temp[i]+word_vectors[token][i] for i in range(len(temp))]\n",
    "    trans_vectors.append(temp)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract speech features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "speech_features = []\n",
    "for feature in speech:\n",
    "    feature = feature[:-5]\n",
    "    temp = []\n",
    "    ss = feature.split(',')\n",
    "    temp = [float(ele) for ele in ss]\n",
    "    speech_features.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate two kinds of features together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2742, 1582)\n",
      "(2742, 50)\n",
      "(2742, 1632)\n"
     ]
    }
   ],
   "source": [
    "speech_features = np.asarray(speech_features)\n",
    "text_features = np.asarray(trans_vectors)\n",
    "new_features = np.concatenate((speech_features,text_features),axis = 1)\n",
    "print(speech_features.shape)\n",
    "print(text_features.shape)\n",
    "print(new_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary classification using speech feature. The accuracy is 87.5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.875\n"
     ]
    }
   ],
   "source": [
    "#speech feature\n",
    "label_set = set(labels)\n",
    "score = 0.0\n",
    "for label in label_set:\n",
    "    new_labels = [ 1 if label == ele else 0 for ele in labels ]\n",
    "    wclf = svm.SVC(kernel='rbf', class_weight='balanced')\n",
    "    predicted = cross_val_predict(wclf, speech_features, new_labels)\n",
    "    score += metrics.accuracy_score(new_labels, predicted)\n",
    "print(score/8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary classification using text feature. The accuracy is 62.6%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.626094091904\n"
     ]
    }
   ],
   "source": [
    "#text feature\n",
    "score = 0.0\n",
    "for label in label_set:\n",
    "    new_labels = [ 1 if label == ele else 0 for ele in labels ]\n",
    "    wclf = svm.SVC(kernel='rbf', class_weight='balanced')\n",
    "    predicted = cross_val_predict(wclf, trans_vectors, new_labels)\n",
    "    score += metrics.accuracy_score(new_labels, predicted)\n",
    "print(score/8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary classification using concatenated feature. Looks like the text feature doesn't\n",
    "### improve the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.875\n"
     ]
    }
   ],
   "source": [
    "label_set = set(labels)\n",
    "score = 0.0\n",
    "for label in label_set:\n",
    "    new_labels = [ 1 if label == ele else 0 for ele in labels ]\n",
    "    wclf = svm.SVC(kernel='rbf', class_weight='balanced')\n",
    "    predicted = cross_val_predict(wclf, new_features, new_labels)\n",
    "    score += metrics.accuracy_score(new_labels, predicted)\n",
    "print(score/8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-class classification \n",
    "\n",
    "|Feature Type | Accuracy |\n",
    "|---|---|\n",
    "| Speech Feature| 24.5% |\n",
    "| Text Feature  | 24.6% |\n",
    "| Concatenated  | 24.8% |\n",
    "\n",
    "### The text feature improves the result a little bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###multi-class classification\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(labels)\n",
    "labels = le.transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wclf = svm.SVC(kernel='linear', class_weight='balanced')\n",
    "predicted = cross_val_predict(wclf, new_features, labels)\n",
    "metrics.accuracy_score(labels, predicted)\n",
    "\n",
    "#accuracy 0.24762946754"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wclf = svm.SVC(kernel='linear', class_weight='balanced')\n",
    "predicted = cross_val_predict(wclf, speech_features, labels)\n",
    "metrics.accuracy_score(labels, predicted)\n",
    "#accuracy 0.245441283735"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wclf = svm.SVC(kernel='linear', class_weight='balanced')\n",
    "predicted = cross_val_predict(wclf, text_features, labels)\n",
    "metrics.accuracy_score(labels, predicted)\n",
    "#accuracy 0.246170678337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py3k]",
   "language": "python",
   "name": "Python [py3k]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
